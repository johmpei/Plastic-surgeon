from flask import Flask, request, jsonify
import faiss
import numpy as np
import os

app = Flask(__name__)

# ğŸ”¹ èµ·å‹•æ™‚ã«é‡ãŸã„ SentenceTransformer ã‚’èª­ã¿è¾¼ã¾ãªã„
# ğŸ”¹ ä»£ã‚ã‚Šã«ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒšãƒ¼ã‚¸ãƒãƒƒãƒ—ã ã‘èª­ã¿è¾¼ã‚€
index = faiss.read_index("faiss_index.idx")

with open("doc_map.txt", "r", encoding="utf-8") as f:
    doc_map = {int(line.split("\t")[0]): line.strip().split("\t")[1] for line in f}

@app.route("/search")
def search():
    query = request.args.get("query")
    if not query:
        return jsonify({"error": "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼"}), 400

    # ğŸ”¥ ãƒ¢ãƒ‡ãƒ«ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãŸã³ã«èª­ã¿è¾¼ã‚€ï¼ˆã“ã“ãŒãƒã‚¤ãƒ³ãƒˆï¼ï¼‰
    from sentence_transformers import SentenceTransformer
    model = SentenceTransformer("all-MiniLM-L6-v2")
    q_vector = model.encode([query], convert_to_numpy=True)
    D, I = index.search(q_vector, k=3)

    results = []
    for idx in I[0]:
        results.append({
            "page": doc_map.get(idx),
            "score": float(D[0][list(I[0]).index(idx)])
        })

    return jsonify({
        "query": query,
        "results": results
    })

# ğŸ”§ Renderã§å¿…è¦ãªãƒãƒ¼ãƒˆè¨­å®š
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
