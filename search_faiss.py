
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

model = SentenceTransformer("all-MiniLM-L6-v2")
index = faiss.read_index("faiss_index.idx")

with open("doc_map.txt", "r", encoding="utf-8") as f:
    doc_map = {int(line.split("\t")[0]): line.strip().split("\t")[1] for line in f}

query = input("ğŸ” æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„è³ªå•ã‚’å…¥åŠ›ã—ã¦ã­ï¼š\n> ")
q_vector = model.encode([query], convert_to_numpy=True)
D, I = index.search(q_vector, k=3)

print("\nğŸ” é–¢é€£ã™ã‚‹ãƒšãƒ¼ã‚¸ï¼š")
for rank, idx in enumerate(I[0]):
    print(f"{rank+1}. {doc_map[idx]}")
